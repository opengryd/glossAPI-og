# OlmOCR-2 (CUDA/vLLM + MPS/MLX) environment
#
# Copy this file to .env_olmocr and adjust the paths for your machine:
#   cp dependency_setup/.env_olmocr.example dependency_setup/.env_olmocr
# Then source it before running the pipeline:
#   source dependency_setup/.env_olmocr

# ---------------------------------------------------------------------------
# Shared weights root
# ---------------------------------------------------------------------------
export GLOSSAPI_WEIGHTS_ROOT=/path/to/glossAPI/model_weights

# ---------------------------------------------------------------------------
# Python binary inside the OlmOCR venv.
# ---------------------------------------------------------------------------
export GLOSSAPI_OLMOCR_PYTHON=/path/to/glossAPI/dependency_setup/.venvs/olmocr-py312/bin/python

# ---------------------------------------------------------------------------
# OCR control
# ENABLE_OCR=1   → enables the OlmOCR pipeline subprocess (CUDA or MPS)
# ENABLE_STUB=0  → disables fallback stub output (set 1 only for tests)
# ---------------------------------------------------------------------------
export GLOSSAPI_OLMOCR_ENABLE_OCR=1
export GLOSSAPI_OLMOCR_ENABLE_STUB=0

# ---------------------------------------------------------------------------
# Device for inference: mps (macOS Apple Silicon) | cuda (Linux GPU)
# Auto-detected from torch if not set.
# ---------------------------------------------------------------------------
export GLOSSAPI_OLMOCR_DEVICE="mps"

# ---------------------------------------------------------------------------
# CUDA / vLLM path
# ---------------------------------------------------------------------------
# HuggingFace model identifier (default: allenai/olmOCR-2-7B-1025-FP8).
# export GLOSSAPI_OLMOCR_MODEL=allenai/olmOCR-2-7B-1025-FP8

# Override CUDA model weights directory (default: GLOSSAPI_WEIGHTS_ROOT/olmocr/).
# export GLOSSAPI_OLMOCR_MODEL_DIR=/path/to/glossAPI/model_weights/olmocr

# VRAM fraction for vLLM KV-cache (default: 0.85).
# export GLOSSAPI_OLMOCR_GPU_MEMORY_UTILIZATION=0.85

# Upper bound (tokens) for KV-cache allocation (default: 8192).
# export GLOSSAPI_OLMOCR_MAX_MODEL_LEN=8192

# Tensor parallel size for vLLM (default: 1).
# export GLOSSAPI_OLMOCR_TENSOR_PARALLEL_SIZE=1

# Path to vLLM CLI inference script (default: package-embedded vllm_cli.py).
# export GLOSSAPI_OLMOCR_VLLM_SCRIPT=/path/to/glossAPI/src/glossapi/ocr/olmocr/vllm_cli.py

# Extra LD_LIBRARY_PATH entries for CUDA subprocesses (e.g. /usr/local/cuda/lib64).
# export GLOSSAPI_OLMOCR_LD_LIBRARY_PATH=/usr/local/cuda/lib64

# External vLLM server URL (skip local subprocess when set).
# export GLOSSAPI_OLMOCR_SERVER=http://localhost:8000
# export GLOSSAPI_OLMOCR_API_KEY=

# ---------------------------------------------------------------------------
# OlmOCR CLI tuning (CLI subprocess path only)
# ---------------------------------------------------------------------------
# Longest-side dimension for PDF page rendering.
# export GLOSSAPI_OLMOCR_TARGET_IMAGE_DIM=2048

# Number of OlmOCR pipeline workers.
# export GLOSSAPI_OLMOCR_WORKERS=2

# PDF pages per work item group.
# export GLOSSAPI_OLMOCR_PAGES_PER_GROUP=8

# ---------------------------------------------------------------------------
# MPS / MLX path (macOS Apple Silicon)
# ---------------------------------------------------------------------------
# HuggingFace MLX model identifier (default: mlx-community/olmOCR-2-7B-1025-4bit).
# export GLOSSAPI_OLMOCR_MLX_MODEL=mlx-community/olmOCR-2-7B-1025-4bit

# Override MLX model weights directory (default: GLOSSAPI_WEIGHTS_ROOT/olmocr-mlx/).
# export GLOSSAPI_OLMOCR_MLX_MODEL_DIR=/path/to/glossAPI/model_weights/olmocr-mlx

# Path to MLX inference script (default: package-embedded mlx_cli.py).
# export GLOSSAPI_OLMOCR_MLX_SCRIPT=/path/to/glossAPI/src/glossapi/ocr/olmocr/mlx_cli.py

# ---------------------------------------------------------------------------
# Misc
# ---------------------------------------------------------------------------
export GLOSSAPI_SKIP_DOCLING_BOOT=1
